{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning with Bias-Aware Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook integrates bias-aware techniques into the fine-tuning process. It includes:\n",
    "1. Analysis of verbosity and position bias.\n",
    "2. Data augmentation to mitigate position bias.\n",
    "3. Fine-tuning a DeBERTa-small model using LoRA on the augmented dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers peft accelerate bitsandbytes torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data and Analyze Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Verbosity Analysis ---\n",
      "Avg word count for A: 204.37\n",
      "Avg word count for B: 205.18\n",
      "--- Position Bias Analysis ---\n",
      "Total samples: 57477\n",
      "Model A wins: 20064 (34.91%)\n",
      "Model B wins: 19652 (34.19%)\n",
      "Ties: 17761 (30.90%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from peft import get_peft_model, LoraConfig\n",
    "\n",
    "# Load data\n",
    "#path = '/kaggle/input/llm-classification-finetuning/'           #for kaggle submission\n",
    "path = 'dataset/'                                              #for local test\n",
    "train_df = pd.read_csv('dataset/train.csv')\n",
    "test_df = pd.read_csv('dataset/test.csv')\n",
    "submission_df = pd.read_csv('dataset/sample_submission.csv')\n",
    "\n",
    "# --- Verbosity Bias Analysis ---\n",
    "train_df['len_a'] = train_df['response_a'].str.len()\n",
    "train_df['len_b'] = train_df['response_b'].str.len()\n",
    "train_df['word_count_a'] = train_df['response_a'].apply(lambda x: len(str(x).split()))\n",
    "train_df['word_count_b'] = train_df['response_b'].apply(lambda x: len(str(x).split()))\n",
    "print('--- Verbosity Analysis ---')\n",
    "print(f\"Avg word count for A: {train_df['word_count_a'].mean():.2f}\")\n",
    "print(f\"Avg word count for B: {train_df['word_count_b'].mean():.2f}\")\n",
    "\n",
    "# --- Position Bias Analysis ---\n",
    "model_a_wins = train_df['winner_model_a'].sum()\n",
    "model_b_wins = train_df['winner_model_b'].sum()\n",
    "ties = train_df['winner_tie'].sum()\n",
    "total = len(train_df)\n",
    "print('--- Position Bias Analysis ---')\n",
    "print(f'Total samples: {total}')\n",
    "print(f'Model A wins: {model_a_wins} ({model_a_wins/total:.2%})')\n",
    "print(f'Model B wins: {model_b_wins} ({model_b_wins/total:.2%})')\n",
    "print(f'Ties: {ties} ({ties/total:.2%})')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Augmentation and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare original labels\n",
    "conditions = [train_df['winner_model_a'] == 1, train_df['winner_model_b'] == 1, train_df['winner_tie'] == 1]\n",
    "choices = [0, 1, 2] # 0: model_a, 1: model_b, 2: tie\n",
    "train_df['label'] = np.select(conditions, choices, default=-1)\n",
    "train_df = train_df[train_df['label'] != -1].copy()\n",
    "\n",
    "# Create combined text field\n",
    "def create_text(row):\n",
    "    return f\"\"\"prompt: {row['prompt']}\n",
    "\n",
    "response_a: {row['response_a']}\n",
    "\n",
    "response_b: {row['response_b']}\"\"\"\n",
    "\n",
    "train_df['text'] = train_df.apply(create_text, axis=1)\n",
    "test_df['text'] = test_df.apply(create_text, axis=1)\n",
    "\n",
    "# Split augmented train data for validation\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_df['text'], train_df['label'], test_size=0.1, random_state=42, stratify=train_df['label']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "model_name = 'microsoft/deberta-v3-small'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_texts.tolist(), truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(test_df['text'].tolist(), truncation=True, padding=True, max_length=512)\n",
    "\n",
    "class PreferenceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = PreferenceDataset(train_encodings, train_labels.tolist())\n",
    "val_dataset = PreferenceDataset(val_encodings, val_labels.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Setup and LoRA Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=3,\n",
    "    load_in_8bit=True,\n",
    "    device_map='auto'\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16, # Rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=['query_proj', 'value_proj'],\n",
    "    lora_dropout=0.05,\n",
    "    bias='none',\n",
    "    task_type=\"SEQ_CLS\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results_bias_aware',\n",
    "    num_train_epochs=1, # A single epoch for a quick baseline\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs_bias_aware',\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prediction and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "test_dataset = TestDataset(test_encodings)\n",
    "\n",
    "predictions = trainer.predict(test_dataset)\n",
    "probs = torch.nn.functional.softmax(torch.from_numpy(predictions.predictions), dim=-1).numpy()\n",
    "\n",
    "submission_df['winner_model_a'] = probs[:, 0]\n",
    "submission_df['winner_model_b'] = probs[:, 1]\n",
    "submission_df['winner_tie'] = probs[:, 2]\n",
    "\n",
    "submission_df.to_csv('submission_finetuned_bias_aware.csv', index=False)\n",
    "\n",
    "submission_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpytc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
