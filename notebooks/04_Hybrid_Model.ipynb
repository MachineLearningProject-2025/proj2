{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6800762",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91830cb",
   "metadata": {},
   "source": [
    "## Module Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a91ab6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b120cc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7afa3405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, log_loss\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebed80a",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fccccdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../dataset/train.csv')\n",
    "test_df = pd.read_csv('../dataset/test.csv')\n",
    "submission_df = pd.read_csv('../dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "864ce00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_features = [\n",
    "    'len_diff', 'punc_diff',\n",
    "    'sent_count_diff', \n",
    "    'lexical_div_diff',\n",
    "    'repetition_diff', \n",
    "    # 'subjectivity_diff',\n",
    "    'comma_ratio_diff', \n",
    "    # 'avg_word_len_diff'\n",
    "]\n",
    "\n",
    "target_words = [\n",
    "    'company', 'brace', 'knee', 'progression', \n",
    "    'apologize', 'sorry'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06dd385a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(df):\n",
    "    df['len_a'] = df['response_a'].str.len()\n",
    "    df['len_b'] = df['response_b'].str.len()\n",
    "    df['punc_a'] = df['response_a'].apply(lambda x: len(re.findall(r'[!?,;:]', str(x))))\n",
    "    df['punc_b'] = df['response_b'].apply(lambda x: len(re.findall(r'[!?,;:]', str(x))))\n",
    "    df['sent_a'] = df['response_a'].apply(lambda x: len(re.findall(r'[.!?]', str(x))))\n",
    "    df['sent_b'] = df['response_b'].apply(lambda x: len(re.findall(r'[.!?]', str(x))))\n",
    "\n",
    "    def ling_feat(text):\n",
    "        words = re.findall(r'\\b\\w+\\b', str(text).lower())\n",
    "        uniq = set(words)\n",
    "        lex_div = len(uniq)/(len(words)+1e-9)\n",
    "        repetition = 1 - len(uniq)/(len(words)+1e-9)\n",
    "        blob = TextBlob(str(text))\n",
    "        subj = blob.sentiment.subjectivity\n",
    "        return lex_div, repetition, subj\n",
    "    \n",
    "    for side in ['a', 'b']:\n",
    "        df[[f'lex_{side}', f'rep_{side}', f'subj_{side}']] = df[f'response_{side}'].apply(\n",
    "            lambda x: pd.Series(ling_feat(x))\n",
    "        )\n",
    "    \n",
    "    df['comma_a'] = df['response_a'].apply(lambda x: len(re.findall(r'[;,]', str(x))) / (len(x.split()) + 1e-9))\n",
    "    df['comma_b'] = df['response_b'].apply(lambda x: len(re.findall(r'[;,]', str(x))) / (len(x.split()) + 1e-9))\n",
    "    # df['avglen_a'] = df['response_a'].apply(lambda x: np.mean([len(w) for w in str(x).split()]) if len(str(x).split()) > 0 else 0)\n",
    "    # df['avglen_b'] = df['response_b'].apply(lambda x: np.mean([len(w) for w in str(x).split()]) if len(str(x).split()) > 0 else 0)\n",
    "\n",
    "    # diff features\n",
    "    df['len_diff'] = df['len_a'] - df['len_b']\n",
    "    df['punc_diff'] = df['punc_a'] - df['punc_b']\n",
    "    df['sent_count_diff'] = df['sent_a'] - df['sent_b']\n",
    "    df['lexical_div_diff'] = df['lex_a'] - df['lex_b']\n",
    "    df['repetition_diff'] = df['rep_a'] - df['rep_b']\n",
    "    # df['subjectivity_diff'] = df['subj_a'] - df['subj_b']\n",
    "    df['comma_ratio_diff'] = df['comma_a'] - df['comma_b']\n",
    "    # df['avg_word_len_diff'] = df['avglen_a'] - df['avglen_b']\n",
    "    \n",
    "    # --- keyword presence ---\n",
    "    text_cols = df[['prompt', 'response_a', 'response_b']].astype(str).agg(' '.join, axis=1)\n",
    "    for word in target_words:\n",
    "        df[f'contains_{word}'] = text_cols.str.contains(fr'\\b{word}\\b', case=False, na=False).astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a7b6c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_features(train_df)\n",
    "test_df = get_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fb8d297",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['label'] = np.select(\n",
    "    [train_df['winner_model_a']==1, train_df['winner_model_b']==1, train_df['winner_tie']==1],\n",
    "    [0,1,2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d88ac9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_features = [f'contains_{w}' for w in target_words]\n",
    "all_features = significant_features + keyword_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa78c816",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[all_features]\n",
    "y = train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4d49d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature summary (first rows):\n",
      "                        dtype  is_binary  n_unique           var        skew  \\\n",
      "feature                                                                        \n",
      "len_diff                int64      False      6041  1.205707e+06   -1.124580   \n",
      "punc_diff               int64      False       313  3.658851e+02    6.378323   \n",
      "sent_count_diff         int64      False       255  1.972592e+02   -2.359540   \n",
      "lexical_div_diff      float64      False     55950  3.080705e-02    0.025245   \n",
      "repetition_diff       float64      False     55950  3.080705e-02   -0.025245   \n",
      "comma_ratio_diff      float64      False     51816  1.734652e+00 -165.425305   \n",
      "contains_company        int64       True         2  4.487974e-02    4.275875   \n",
      "contains_brace          int64       True         2  2.879821e-03   18.527488   \n",
      "contains_knee           int64       True         2  3.778502e-03   16.145383   \n",
      "contains_progression    int64       True         2  7.699548e-03   11.219919   \n",
      "contains_apologize      int64       True         2  4.252482e-02    4.417817   \n",
      "contains_sorry          int64       True         2  5.291572e-02    3.859933   \n",
      "\n",
      "                      outlier_ratio  low_variance           recommended  \n",
      "feature                                                                  \n",
      "len_diff                   0.078344         False          RobustScaler  \n",
      "punc_diff                  0.094942         False          RobustScaler  \n",
      "sent_count_diff            0.104424         False          RobustScaler  \n",
      "lexical_div_diff           0.064565         False          RobustScaler  \n",
      "repetition_diff            0.064565         False          RobustScaler  \n",
      "comma_ratio_diff           0.073421         False          RobustScaler  \n",
      "contains_company           0.047097         False  passthrough (binary)  \n",
      "contains_brace             0.002888         False  passthrough (binary)  \n",
      "contains_knee              0.003793         False  passthrough (binary)  \n",
      "contains_progression       0.007760         False  passthrough (binary)  \n",
      "contains_apologize         0.044505         False  passthrough (binary)  \n",
      "contains_sorry             0.056057         False  passthrough (binary)  \n",
      "\n",
      "Groups:\n",
      "  binary_cols: ['contains_company', 'contains_brace', 'contains_knee', 'contains_progression', 'contains_apologize', 'contains_sorry']\n",
      "  robust_cols: ['comma_ratio_diff', 'len_diff', 'lexical_div_diff', 'punc_diff', 'repetition_diff', 'sent_count_diff']\n",
      "  std_cols: []\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# 분석 및 혼합 스케일링(열별로 StandardScaler / RobustScaler / 그대로 유지)\n",
    "\n",
    "# X, all_features 변수가 이미 존재한다고 가정\n",
    "df = X.copy()\n",
    "\n",
    "# 기본 통계량 & 이상치/분산 계산\n",
    "summary = []\n",
    "for col in df.columns:\n",
    "  vals = df[col].dropna().astype(float)\n",
    "  n_unique = df[col].nunique(dropna=True)\n",
    "  is_binary = set(vals.unique()).issubset({0.0, 1.0}) or n_unique == 2\n",
    "  var = vals.var()\n",
    "  skew = vals.skew()\n",
    "  q1, q3 = vals.quantile(0.25), vals.quantile(0.75)\n",
    "  iqr = q3 - q1\n",
    "  lower, upper = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "  outlier_mask = (vals < lower) | (vals > upper)\n",
    "  outlier_ratio = outlier_mask.sum() / max(len(vals), 1)\n",
    "  low_variance = var < 1e-4  # 임계값은 데이터에 따라 조정 가능\n",
    "  high_skew = abs(skew) > 1.0\n",
    "\n",
    "  # 스케일러 권장: 이진 변수는 그대로, 이상치가 많거나 왜도가 큰 경우 Robust, 아니면 Standard\n",
    "  if is_binary:\n",
    "    recommended = 'passthrough (binary)'\n",
    "  elif outlier_ratio > 0.05 or high_skew:\n",
    "    recommended = 'RobustScaler'\n",
    "  else:\n",
    "    recommended = 'StandardScaler'\n",
    "\n",
    "  summary.append({\n",
    "    'feature': col,\n",
    "    'dtype': str(df[col].dtype),\n",
    "    'n_unique': n_unique,\n",
    "    'is_binary': is_binary,\n",
    "    'var': var,\n",
    "    'skew': skew,\n",
    "    'q1': q1,\n",
    "    'q3': q3,\n",
    "    'iqr': iqr,\n",
    "    'outlier_ratio': outlier_ratio,\n",
    "    'low_variance': low_variance,\n",
    "    'recommended': recommended\n",
    "  })\n",
    "\n",
    "summary_df = pd.DataFrame(summary).set_index('feature')\n",
    "print(\"Feature summary (first rows):\")\n",
    "print(summary_df[['dtype', 'is_binary', 'n_unique', 'var', 'skew', 'outlier_ratio', 'low_variance', 'recommended']].head(20))\n",
    "\n",
    "# 그룹 분류\n",
    "binary_cols = summary_df[summary_df['is_binary']].index.tolist()\n",
    "robust_cols = summary_df[summary_df['recommended'] == 'RobustScaler'].index.difference(binary_cols).tolist()\n",
    "std_cols = summary_df[summary_df['recommended'] == 'StandardScaler'].index.difference(binary_cols).tolist()\n",
    "\n",
    "print(\"\\nGroups:\")\n",
    "print(\"  binary_cols:\", binary_cols)\n",
    "print(\"  robust_cols:\", robust_cols)\n",
    "print(\"  std_cols:\", std_cols)\n",
    "\n",
    "# ColumnTransformer 구성 (빈 그룹은 생략)\n",
    "transformers = []\n",
    "if std_cols:\n",
    "  transformers.append(('std', StandardScaler(), std_cols))\n",
    "if robust_cols:\n",
    "  transformers.append(('robust', RobustScaler(), robust_cols))\n",
    "# passthrough for binary (유지)\n",
    "if binary_cols:\n",
    "  transformers.append(('passthrough_binary', 'passthrough', binary_cols))\n",
    "\n",
    "if not transformers:\n",
    "  raise RuntimeError(\"No features to transform. Check X/all_features.\")\n",
    "\n",
    "col_transformer = ColumnTransformer(transformers, remainder='drop', sparse_threshold=0)\n",
    "\n",
    "# fit + transform -> DataFrame으로 복원\n",
    "X_scaled_arr = col_transformer.fit_transform(df)\n",
    "# ColumnTransformer 순서를 이용해 컬럼명 재구성\n",
    "out_cols = []\n",
    "for name, _, cols in transformers:\n",
    "  if cols == 'passthrough' or name.startswith('passthrough'):\n",
    "    # passthrough 사용한 경우, 실제 컬럼 순서가 입력 df에서 유지되므로 cols는 리스트로 받음\n",
    "    out_cols.extend(cols if isinstance(cols, (list, tuple)) else list(cols))\n",
    "  else:\n",
    "    out_cols.extend(cols)\n",
    "X_scaled_df = pd.DataFrame(X_scaled_arr, columns=out_cols, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83f64804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comma_ratio_diff</th>\n",
       "      <th>len_diff</th>\n",
       "      <th>lexical_div_diff</th>\n",
       "      <th>punc_diff</th>\n",
       "      <th>repetition_diff</th>\n",
       "      <th>sent_count_diff</th>\n",
       "      <th>contains_company</th>\n",
       "      <th>contains_brace</th>\n",
       "      <th>contains_knee</th>\n",
       "      <th>contains_progression</th>\n",
       "      <th>contains_apologize</th>\n",
       "      <th>contains_sorry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.509879</td>\n",
       "      <td>3.952550</td>\n",
       "      <td>-0.550103</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.550103</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.247947</td>\n",
       "      <td>-0.634638</td>\n",
       "      <td>-0.713681</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>0.713681</td>\n",
       "      <td>-1.777778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.727202</td>\n",
       "      <td>-1.084223</td>\n",
       "      <td>0.816672</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>-0.816672</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.382777</td>\n",
       "      <td>1.921708</td>\n",
       "      <td>-0.593601</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.593601</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.069289</td>\n",
       "      <td>0.626335</td>\n",
       "      <td>-0.709755</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.709755</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57472</th>\n",
       "      <td>1.690206</td>\n",
       "      <td>-0.190985</td>\n",
       "      <td>1.050461</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-1.050461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57473</th>\n",
       "      <td>0.436278</td>\n",
       "      <td>-0.007117</td>\n",
       "      <td>0.239260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.239260</td>\n",
       "      <td>-1.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57474</th>\n",
       "      <td>-0.402496</td>\n",
       "      <td>8.451957</td>\n",
       "      <td>-0.398586</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>0.398586</td>\n",
       "      <td>10.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57475</th>\n",
       "      <td>0.232915</td>\n",
       "      <td>-0.633452</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.009375</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57476</th>\n",
       "      <td>-1.322622</td>\n",
       "      <td>-0.608541</td>\n",
       "      <td>3.816926</td>\n",
       "      <td>-0.583333</td>\n",
       "      <td>-3.816926</td>\n",
       "      <td>-0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57477 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       comma_ratio_diff  len_diff  lexical_div_diff  punc_diff  \\\n",
       "0             -0.509879  3.952550         -0.550103   3.333333   \n",
       "1             -0.247947 -0.634638         -0.713681  -0.750000   \n",
       "2             -0.727202 -1.084223          0.816672  -1.250000   \n",
       "3              0.382777  1.921708         -0.593601   1.666667   \n",
       "4              0.069289  0.626335         -0.709755   0.833333   \n",
       "...                 ...       ...               ...        ...   \n",
       "57472          1.690206 -0.190985          1.050461   0.250000   \n",
       "57473          0.436278 -0.007117          0.239260   0.000000   \n",
       "57474         -0.402496  8.451957         -0.398586   4.416667   \n",
       "57475          0.232915 -0.633452          0.009375  -0.333333   \n",
       "57476         -1.322622 -0.608541          3.816926  -0.583333   \n",
       "\n",
       "       repetition_diff  sent_count_diff  contains_company  contains_brace  \\\n",
       "0             0.550103         3.000000               0.0             0.0   \n",
       "1             0.713681        -1.777778               0.0             0.0   \n",
       "2            -0.816672        -0.666667               0.0             0.0   \n",
       "3             0.593601         1.222222               0.0             0.0   \n",
       "4             0.709755         0.222222               0.0             0.0   \n",
       "...                ...              ...               ...             ...   \n",
       "57472        -1.050461         1.000000               0.0             0.0   \n",
       "57473        -0.239260        -1.222222               0.0             0.0   \n",
       "57474         0.398586        10.111111               0.0             0.0   \n",
       "57475        -0.009375        -0.666667               0.0             0.0   \n",
       "57476        -3.816926        -0.444444               0.0             0.0   \n",
       "\n",
       "       contains_knee  contains_progression  contains_apologize  contains_sorry  \n",
       "0                0.0                   0.0                 0.0             0.0  \n",
       "1                0.0                   0.0                 0.0             0.0  \n",
       "2                0.0                   0.0                 0.0             0.0  \n",
       "3                0.0                   0.0                 0.0             0.0  \n",
       "4                0.0                   0.0                 0.0             0.0  \n",
       "...              ...                   ...                 ...             ...  \n",
       "57472            0.0                   0.0                 0.0             0.0  \n",
       "57473            0.0                   0.0                 0.0             0.0  \n",
       "57474            0.0                   0.0                 0.0             0.0  \n",
       "57475            0.0                   0.0                 0.0             0.0  \n",
       "57476            0.0                   0.0                 0.0             0.0  \n",
       "\n",
       "[57477 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b38574e",
   "metadata": {},
   "source": [
    "## LoRA Embedding Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bc512b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
