# model_trainer.py

import pandas as pd
import numpy as np
import re
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, StackingClassifier
from lightgbm import LGBMClassifier
from sklearn.metrics import log_loss, classification_report
import matplotlib.pyplot as plt
import seaborn as sns
from sentence_transformers import SentenceTransformer
from sklearn.metrics import confusion_matrix

# --- ì„¤ì • ë³€ìˆ˜ ---
EMBEDDING_MODEL_NAME = 'all-MiniLM-L6-v2'

def clean_prompt(s):
    """í”„ë¡¬í”„íŠ¸ì—ì„œ ë¶ˆí•„ìš”í•œ êµ¬ë‘ì  ì œê±° (ì„ë² ë”© ê°œì„  ëª©ì )"""
    return re.sub(r'["\'\[\]]', '', str(s))

def generate_embeddings(df, model):
    """
    Prompt + Response í…ìŠ¤íŠ¸ë¥¼ ê²°í•©í•˜ê³  MiniLM ì„ë² ë”©ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    print(f"â¡ï¸ Generating embeddings using {EMBEDDING_MODEL_NAME}...")
    
    df['prompt_clean'] = df['prompt'].apply(clean_prompt)
    df['text_a'] = df['prompt_clean'] + ' ' + df['response_a']
    df['text_b'] = df['prompt_clean'] + ' ' + df['response_b']
    
    # Prompt, Response A, Response B ì„ë² ë”© ì¶”ì¶œ
    emb_a = model.encode(df['text_a'].tolist(), show_progress_bar=True)
    emb_b = model.encode(df['text_b'].tolist(), show_progress_bar=True)
    prompt_emb = model.encode(df['prompt_clean'].tolist(), show_progress_bar=True)
    
    # ì‘ë‹µ ê°„ ì°¨ì´ ë²¡í„° (A - B)
    emb_diff = emb_a - emb_b
    
    return emb_diff, prompt_emb

def build_hybrid_data(emb_diff, prompt_emb, X_train_scaled):
    """
    ì„ë² ë”© ë²¡í„°ì™€ ìŠ¤ì¼€ì¼ë§ëœ í…Œì´ë¸” íŠ¹ì§•ì„ ê²°í•©í•˜ì—¬ ìµœì¢… X ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    print("â¡ï¸ Combining embeddings and tabular features...")
    # X_train_scaled train_dfì˜ ì¸ë±ìŠ¤ ìˆœì„œì™€ ë™ì¼í•´ì•¼ í•¨
    
    # NOTE: í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ë“¤ì–´ì˜¬ ê²½ìš°, X_train_scaledëŠ” í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ íŠ¹ì§•ë§Œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
    # ì´ í•¨ìˆ˜ëŠ” train/test ë³„ë„ë¡œ í˜¸ì¶œí•˜ëŠ” ê²ƒì´ ì•ˆì „í•©ë‹ˆë‹¤.
    
    X_hybrid = np.concatenate([emb_diff, prompt_emb, X_train_scaled.values], axis=1)
    print(f"   Hybrid X shape: {X_hybrid.shape}")
    return X_hybrid

def train_and_evaluate_model(X_train, y_train, X_val, y_val, search_params=True):
    """
    GridSearchCVì™€ StackingClassifierë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ê²€ì¦í•©ë‹ˆë‹¤.
    """
    print("â¡ï¸ Initializing Stacking Classifier...")
    
    # 1. Base models ì •ì˜
    base_models = [
        ('lr', LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs', random_state=42)),
        ('rf', RandomForestClassifier(random_state=42, n_jobs=-1)),
        ('lgb', LGBMClassifier(random_state=42, verbose=-1))]
    
    # 2. Meta model ì •ì˜
    meta_model = LogisticRegression(max_iter=1000, solver='lbfgs', multi_class='multinomial', random_state=42)
    
    # 3. StackingClassifier ì •ì˜
    stacking_model = StackingClassifier(
        estimators=base_models,
        final_estimator=meta_model,
        stack_method='predict_proba',
        cv=3,       # ë‚´ë¶€ Stacking CV
        n_jobs=-1)
        
    if search_params:
        print("â¡ï¸ Performing GridSearchCV for Hyperparameter Tuning (may take time)...")
        # 4. GridSearchë¥¼ ìœ„í•œ íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì„¤ì • (ì›ë³¸ ì½”ë“œ ê¸°ë°˜)
        param_grid = {
            'lgb__n_estimators': [200, 400],
            'lgb__learning_rate': [0.03, 0.05],
            'rf__n_estimators': [100, 200]}

        # 5. GridSearchCV ê°ì‹¸ê¸°
        grid = GridSearchCV(
            estimator=stacking_model,
            param_grid=param_grid,
            scoring='neg_log_loss', # Log Loss ìµœì†Œí™”
            cv=3,                   # ì „ì²´ ëª¨ë¸ì— ëŒ€í•œ CV
            verbose=1,
            n_jobs=-1)
            
        # 6. í•™ìŠµ ìˆ˜í–‰
        grid.fit(X_train, y_train)
        
        # 7. ê²°ê³¼ ì¶œë ¥
        print("\nğŸ† Best Model Found:")
        print(f"   Best Parameters: {grid.best_params_}")
        print(f"   Best CV LogLoss: {-grid.best_score_:.4f}")
        
        final_model = grid.best_estimator_
    else:
        # ê°„ë‹¨ í•™ìŠµ (ë””ë²„ê¹…ìš©)
        print("â¡ï¸ Training Stacking Model without GridSearch...")
        final_model = stacking_model
        final_model.fit(X_train, y_train)

    # 8. ê²€ì¦ ë° í‰ê°€
    y_pred = final_model.predict(X_val)
    y_prob = final_model.predict_proba(X_val)
    
    acc = final_model.score(X_val, y_val)
    loss = log_loss(y_val, y_prob)
    
    print(f"\nğŸ“Š Validation Accuracy: {acc:.4f}")
    print(f"ğŸ“‰ Validation LogLoss: {loss:.4f}")
    
    print("\nClassification Report (Validation):")
    print(classification_report(y_val, y_pred, target_names=['A win', 'B win', 'Tie']))
    
    # ì‹œê°í™”
    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    sns.heatmap(confusion_matrix(y_val, y_pred), annot=True, fmt='d', cmap='Blues', 
                xticklabels=['A win', 'B win', 'Tie'], yticklabels=['A win', 'B win', 'Tie'])
    plt.title("Confusion Matrix (Validation)")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    
    plt.subplot(1, 2, 2)
    try:
        meta = final_model.final_estimator_
        # Meta Model Coefficients (LRì˜ ê²½ìš°)
        coef_df = pd.DataFrame(meta.coef_.T, 
                               index=[name + "_prob" for name, _ in base_models], 
                               columns=['A win', 'B win', 'Tie'])
        coef_df.plot(kind='bar', ax=plt.gca())
        plt.title("Meta Model Feature Importance (LR Coefs)")
        plt.ylabel("Coefficient Value")
        plt.xticks(rotation=45, ha='right')
    except Exception as e:
        print(f"Could not plot meta model coefficients: {e}")

    plt.tight_layout()
    plt.show()

    return final_model, y_prob