{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f137908b",
   "metadata": {
    "papermill": {
     "duration": 0.002967,
     "end_time": "2025-10-31T06:56:21.676686",
     "exception": false,
     "start_time": "2025-10-31T06:56:21.673719",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fine-tuning with KerasNLP and Bias-Aware Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee451c9",
   "metadata": {
    "papermill": {
     "duration": 0.001928,
     "end_time": "2025-10-31T06:56:21.681015",
     "exception": false,
     "start_time": "2025-10-31T06:56:21.679087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook uses the KerasNLP library to fine-tune a DeBERTa model, incorporating the bias-aware data augmentation techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb7e264",
   "metadata": {
    "papermill": {
     "duration": 0.001793,
     "end_time": "2025-10-31T06:56:21.684985",
     "exception": false,
     "start_time": "2025-10-31T06:56:21.683192",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "931d751e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T06:56:21.689754Z",
     "iopub.status.busy": "2025-10-31T06:56:21.689535Z",
     "iopub.status.idle": "2025-10-31T06:56:21.695278Z",
     "shell.execute_reply": "2025-10-31T06:56:21.694766Z"
    },
    "papermill": {
     "duration": 0.009292,
     "end_time": "2025-10-31T06:56:21.696273",
     "exception": false,
     "start_time": "2025-10-31T06:56:21.686981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set Keras 3 backend\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49332803",
   "metadata": {
    "papermill": {
     "duration": 0.001859,
     "end_time": "2025-10-31T06:56:21.700161",
     "exception": false,
     "start_time": "2025-10-31T06:56:21.698302",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Load Data and Analyze Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d6f0536",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T06:56:21.705168Z",
     "iopub.status.busy": "2025-10-31T06:56:21.704773Z",
     "iopub.status.idle": "2025-10-31T06:56:29.981408Z",
     "shell.execute_reply": "2025-10-31T06:56:29.980543Z"
    },
    "papermill": {
     "duration": 8.280574,
     "end_time": "2025-10-31T06:56:29.982704",
     "exception": false,
     "start_time": "2025-10-31T06:56:21.702130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Verbosity Analysis ---\n",
      "Avg word count for A: 204.37\n",
      "Avg word count for B: 205.18\n",
      "--- Position Bias Analysis ---\n",
      "Total samples: 57477\n",
      "Model A wins: 20064 (34.91%)\n",
      "Model B wins: 19652 (34.19%)\n",
      "Ties: 17761 (30.90%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "path = '/kaggle/input/llm-classification-finetuning/'           #for kaggle submission\n",
    "#path = 'dataset/'                                              #for local test\n",
    "train_df = pd.read_csv(path+ 'train.csv')\n",
    "test_df = pd.read_csv(path+ 'test.csv')\n",
    "submission_df = pd.read_csv(path+ 'sample_submission.csv')\n",
    "\n",
    "# --- Verbosity Bias Analysis ---\n",
    "train_df['len_a'] = train_df['response_a'].str.len()\n",
    "train_df['len_b'] = train_df['response_b'].str.len()\n",
    "train_df['word_count_a'] = train_df['response_a'].apply(lambda x: len(str(x).split()))\n",
    "train_df['word_count_b'] = train_df['response_b'].apply(lambda x: len(str(x).split()))\n",
    "print('--- Verbosity Analysis ---')\n",
    "print(f\"Avg word count for A: {train_df['word_count_a'].mean():.2f}\")\n",
    "print(f\"Avg word count for B: {train_df['word_count_b'].mean():.2f}\")\n",
    "\n",
    "# --- Position Bias Analysis ---\n",
    "model_a_wins = train_df['winner_model_a'].sum()\n",
    "model_b_wins = train_df['winner_model_b'].sum()\n",
    "ties = train_df['winner_tie'].sum()\n",
    "total = len(train_df)\n",
    "print('--- Position Bias Analysis ---')\n",
    "print(f'Total samples: {total}')\n",
    "print(f'Model A wins: {model_a_wins} ({model_a_wins/total:.2%})')\n",
    "print(f'Model B wins: {model_b_wins} ({model_b_wins/total:.2%})')\n",
    "print(f'Ties: {ties} ({ties/total:.2%})')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a321a7e",
   "metadata": {
    "papermill": {
     "duration": 0.001988,
     "end_time": "2025-10-31T06:56:29.987370",
     "exception": false,
     "start_time": "2025-10-31T06:56:29.985382",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e8b373b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T06:56:29.992396Z",
     "iopub.status.busy": "2025-10-31T06:56:29.992183Z",
     "iopub.status.idle": "2025-10-31T06:56:30.655642Z",
     "shell.execute_reply": "2025-10-31T06:56:30.654907Z"
    },
    "papermill": {
     "duration": 0.667524,
     "end_time": "2025-10-31T06:56:30.657040",
     "exception": false,
     "start_time": "2025-10-31T06:56:29.989516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare original labels\n",
    "conditions = [train_df['winner_model_a'] == 1, train_df['winner_model_b'] == 1, train_df['winner_tie'] == 1]\n",
    "choices = [0, 1, 2] # 0: model_a, 1: model_b, 2: tie\n",
    "train_df['label'] = np.select(conditions, choices, default=-1)\n",
    "train_df = train_df[train_df['label'] != -1].copy()\n",
    "\n",
    "# Create combined text field\n",
    "def create_text(row):\n",
    "    return f\"\"\"prompt: {row['prompt']}\n",
    "\n",
    "response_a: {row['response_a']}\n",
    "\n",
    "response_b: {row['response_b']}\"\"\"\n",
    "\n",
    "train_df['text'] = train_df.apply(create_text, axis=1)\n",
    "test_df['text'] = test_df.apply(create_text, axis=1)\n",
    "\n",
    "# Split train data for validation\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_df['text'], train_df['label'], test_size=0.1, random_state=42, stratify=train_df['label']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafb48be",
   "metadata": {
    "papermill": {
     "duration": 0.002147,
     "end_time": "2025-10-31T06:56:30.661973",
     "exception": false,
     "start_time": "2025-10-31T06:56:30.659826",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Model Fine-tuning with KerasNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d17936bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T06:56:30.667585Z",
     "iopub.status.busy": "2025-10-31T06:56:30.667048Z",
     "iopub.status.idle": "2025-10-31T07:31:54.679135Z",
     "shell.execute_reply": "2025-10-31T07:31:54.678294Z"
    },
    "papermill": {
     "duration": 2124.347846,
     "end_time": "2025-10-31T07:31:55.011986",
     "exception": false,
     "start_time": "2025-10-31T06:56:30.664140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-31 06:56:32.462301: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761893792.672264      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761893792.725671      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "I0000 00:00:1761893806.895199      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"deberta_v3_text_classifier_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"deberta_v3_text_classifier_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ deberta_v3_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DebertaV3Tokenizer</span>)                     │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">128,001</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ deberta_v3_tokenizer (\u001b[38;5;33mDebertaV3Tokenizer\u001b[0m)                     │                      Vocab size: \u001b[38;5;34m128,001\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"deberta_v3_text_classifier\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"deberta_v3_text_classifier\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ deberta_v3_backbone           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">141,304,320</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DebertaV3Backbone</span>)           │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ deberta_v3_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ pooled_dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ pooled_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,592</span> │ pooled_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ classifier_dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ pooled_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ logits (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,307</span> │ classifier_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ deberta_v3_backbone           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)         │     \u001b[38;5;34m141,304,320\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mDebertaV3Backbone\u001b[0m)           │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ get_item (\u001b[38;5;33mGetItem\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ deberta_v3_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ pooled_dropout (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ pooled_dense (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)               │         \u001b[38;5;34m590,592\u001b[0m │ pooled_dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ classifier_dropout (\u001b[38;5;33mDropout\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ pooled_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ logits (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                 │           \u001b[38;5;34m2,307\u001b[0m │ classifier_dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">141,897,219</span> (541.29 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m141,897,219\u001b[0m (541.29 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">141,897,219</span> (541.29 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m141,897,219\u001b[0m (541.29 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1761893857.360150      60 service.cc:148] XLA service 0x7c1d64011840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1761893857.360786      60 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1761893860.726504      60 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1761893878.752139      60 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6467/6467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2092s\u001b[0m 315ms/step - loss: 1.1060 - sparse_categorical_accuracy: 0.3495 - val_loss: 1.0936 - val_sparse_categorical_accuracy: 0.3756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7c1e18f0e890>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import keras_nlp\n",
    "import tensorflow as tf\n",
    "\n",
    "peft_config = {\"r\": 8}\n",
    "# Load a DeBERTa classifier from the KerasNLP library\n",
    "classifier = keras_nlp.models.DebertaV3Classifier.from_preset(\n",
    "    \"deberta_v3_small_en\",\n",
    "    num_classes=3,\n",
    "    peft_config=peft_config \n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "classifier.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(5e-5),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    jit_compile=True\n",
    ")\n",
    "\n",
    "classifier.summary()\n",
    "\n",
    "# Fit the model\n",
    "classifier.fit(\n",
    "    x=train_texts.tolist(),\n",
    "    y=train_labels.to_numpy(),\n",
    "    validation_data=(val_texts.tolist(), val_labels.to_numpy()),\n",
    "    epochs=1,\n",
    "    batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b468026",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T07:31:55.533418Z",
     "iopub.status.busy": "2025-10-31T07:31:55.533120Z",
     "iopub.status.idle": "2025-10-31T07:33:10.392925Z",
     "shell.execute_reply": "2025-10-31T07:33:10.391914Z"
    },
    "papermill": {
     "duration": 75.122676,
     "end_time": "2025-10-31T07:33:10.394214",
     "exception": false,
     "start_time": "2025-10-31T07:31:55.271538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m719/719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 97ms/step\n",
      "Calibration models trained.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "# Get predictions on the validation set\n",
    "val_logits = classifier.predict(val_texts.tolist(), batch_size=8)\n",
    "val_probs = tf.nn.softmax(val_logits).numpy()\n",
    "\n",
    "# Train a calibrator for each class\n",
    "calibrators = {}\n",
    "for i in range(3):\n",
    "    iso_reg = IsotonicRegression(out_of_bounds='clip')\n",
    "    y_cal = (val_labels.to_numpy() == i).astype(int)\n",
    "    iso_reg.fit(val_probs[:, i], y_cal)\n",
    "    calibrators[i] = iso_reg\n",
    "\n",
    "print(\"Calibration models trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6b7907",
   "metadata": {
    "papermill": {
     "duration": 0.288561,
     "end_time": "2025-10-31T07:33:10.978971",
     "exception": false,
     "start_time": "2025-10-31T07:33:10.690410",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Prediction and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "483e8e13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T07:33:11.643767Z",
     "iopub.status.busy": "2025-10-31T07:33:11.643461Z",
     "iopub.status.idle": "2025-10-31T07:33:14.477861Z",
     "shell.execute_reply": "2025-10-31T07:33:14.477203Z"
    },
    "papermill": {
     "duration": 3.129704,
     "end_time": "2025-10-31T07:33:14.479019",
     "exception": false,
     "start_time": "2025-10-31T07:33:11.349315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136060</td>\n",
       "      <td>0.229521</td>\n",
       "      <td>0.227005</td>\n",
       "      <td>0.543473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211333</td>\n",
       "      <td>0.362297</td>\n",
       "      <td>0.375691</td>\n",
       "      <td>0.262012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1233961</td>\n",
       "      <td>0.362326</td>\n",
       "      <td>0.375721</td>\n",
       "      <td>0.261953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  winner_model_a  winner_model_b  winner_tie\n",
       "0   136060        0.229521        0.227005    0.543473\n",
       "1   211333        0.362297        0.375691    0.262012\n",
       "2  1233961        0.362326        0.375721    0.261953"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "test_logits = classifier.predict(test_df['text'].tolist(), batch_size=8)\n",
    "test_probs = tf.nn.softmax(test_logits).numpy()\n",
    "\n",
    "# Apply calibration\n",
    "calibrated_probs = np.zeros_like(test_probs)\n",
    "for i in range(3):\n",
    "    calibrated_probs[:, i] = calibrators[i].predict(test_probs[:, i])\n",
    "\n",
    "# Normalize probabilities to sum to 1\n",
    "calibrated_probs_sum = np.sum(calibrated_probs, axis=1, keepdims=True)\n",
    "# Add a small epsilon to avoid division by zero\n",
    "normalized_probs = calibrated_probs / (calibrated_probs_sum + 1e-9)\n",
    "\n",
    "# Create submission file\n",
    "submission_df['winner_model_a'] = normalized_probs[:, 0]\n",
    "submission_df['winner_model_b'] = normalized_probs[:, 1]\n",
    "submission_df['winner_tie'] = normalized_probs[:, 2]\n",
    "\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "submission_df.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9809560,
     "sourceId": 86518,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 7429221,
     "modelInstanceId": 4685,
     "sourceId": 6064,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2219.896802,
   "end_time": "2025-10-31T07:33:17.972822",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-31T06:56:18.076020",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
