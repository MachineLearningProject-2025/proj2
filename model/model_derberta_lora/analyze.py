# analyze.py
# --------------------------------------------------
# STAGE 2: í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ, ê²€ì¦ ì„¸íŠ¸ ë¶„ì„, ë³´ì •ê¸° í›ˆë ¨
# --------------------------------------------------

import os
import datasets
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import joblib # ë³´ì •ê¸° ì €ì¥ì„ ìœ„í•´
from datasets import load_dataset
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    Trainer,
    TrainingArguments,
)
from peft import PeftModel
from sklearn.metrics import (
    confusion_matrix,
    classification_report,
    ConfusionMatrixDisplay,
    log_loss,
    accuracy_score
)
from sklearn.isotonic import IsotonicRegression

# ì„¤ì • ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì„í¬íŠ¸
from config import *
from utils import get_strategic_truncate_processor, get_dataset_splits, recreate_val_texts_dataset

def main_analyze():
    print("ğŸš€ STAGE 2: Starting Model Analysis...")
    
    # 0. (í•„ìˆ˜) ë³‘ë ¬ ì²˜ë¦¬ ë¹„í™œì„±í™”
    os.environ["TOKENIZERS_PARALLELISM"] = "false"
    datasets.disable_multiprocessing()

    # 1. í›ˆë ¨ëœ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ
    print(f"Loading trained model and tokenizer from {OUTPUT_DIR}...")
    try:
        # (ì£¼ì˜) í›ˆë ¨ ì‹œ ì‚¬ìš©í•œ ë² ì´ìŠ¤ ëª¨ë¸ì„ ë¨¼ì € ë¡œë“œ
        base_model = AutoModelForSequenceClassification.from_pretrained(
            BASE_MODEL_NAME, num_labels=NUM_LABELS, device_map="auto"
        )
        # LoRA ì–´ëŒ‘í„°(ì €ì¥ëœ ëª¨ë¸)ë¥¼ ë®ì–´ì”Œì›€
        lora_model = PeftModel.from_pretrained(base_model, OUTPUT_DIR)
        
        tokenizer = AutoTokenizer.from_pretrained(OUTPUT_DIR)
    except Exception as e:
        print(f"í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        print(f"{OUTPUT_DIR} ê²½ë¡œì— í›ˆë ¨ëœ ëª¨ë¸ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return
    print("Model and tokenizer loaded.")
    lora_model.eval() # ì¶”ë¡  ëª¨ë“œë¡œ ì„¤ì •

    # 2. ë¶„ì„ì„ ìœ„í•œ ë°ì´í„° ì¬ìƒì„±
    # (í›ˆë ¨ ì‹œì™€ ë™ì¼í•œ ì „ì²˜ë¦¬/ìŠ¤í”Œë¦¿ì„ ìˆ˜í–‰í•˜ì—¬ val_datasetì„ ì¬í˜„)
    try:
        raw_dataset = load_dataset("csv", data_files=DATA_PATH + "train.csv")
    except Exception as e:
        print(f"ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    processor = get_strategic_truncate_processor(tokenizer)
    _, val_dataset = get_dataset_splits(raw_dataset, processor)

    # 3. ì˜ˆì¸¡ ì‹¤í–‰
    print("Running predictions on validation set...")
    # (W&B ë¡œê¹…ì„ ë„ê¸° ìœ„í•´ dummy_args ì‚¬ìš©)
    dummy_args = TrainingArguments(output_dir="./dummy_results", report_to="none")
    trainer = Trainer(model=lora_model, args=dummy_args)
    
    predictions_output = trainer.predict(val_dataset)
    
    # 4. ì˜ˆì¸¡ ê²°ê³¼ ì¶”ì¶œ
    logits = predictions_output.predictions
    y_true = predictions_output.label_ids
    y_probs = torch.nn.functional.softmax(torch.from_numpy(logits), dim=-1).numpy()
    y_pred = np.argmax(y_probs, axis=1)

    # 5. ë³´ì • ì „(Uncalibrated) ë¶„ì„
    print("\n--- ğŸ“Š 1. Uncalibrated Analysis ---")
    acc = accuracy_score(y_true, y_pred)
    loss = log_loss(y_true, y_probs)
    print(f"Validation Accuracy (Uncalibrated): {acc:.4f}")
    print(f"Validation LogLoss (Uncalibrated): {loss:.4f}")

    print("Plotting Confusion Matrix (Uncalibrated)...")
    cm = confusion_matrix(y_true, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=LABELS_MAP)
    disp.plot(cmap=plt.cm.Blues)
    plt.title("Confusion Matrix - Uncalibrated (Validation)")
    plt.savefig(os.path.join(OUTPUT_DIR, "confusion_matrix_uncalibrated.png"))
    plt.show()

    print("\nClassification Report (Uncalibrated):\n")
    print(classification_report(y_true, y_pred, target_names=LABELS_MAP))

    # 6. ì˜¤ë¥˜ ë¶„ì„ (Error Inspection)
    print("\n--- ğŸ˜± 2. Error Analysis ---")
    # ì›ë³¸ í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ val_dataset ì¬ìƒì„±
    val_texts_dataset = recreate_val_texts_dataset(raw_dataset)
    
    df_report = pd.DataFrame(val_texts_dataset)
    df_report["pred_label"] = y_pred
    df_report["true_label"] = y_true

    df_errors = df_report[df_report["true_label"] != df_report["pred_label"]]
    print(f"Total prediction errors: {len(df_errors)}")
    
    # ì˜¤ë¥˜ ìƒìœ„ 10ê°œ ì¶œë ¥
    label_names_dict = {i: name for i, name in enumerate(LABELS_MAP)}
    for index, row in df_errors.head(10).iterrows():
        print("=" * 40)
        print(f"    ğŸ‘‰ ì •ë‹µ (True): {label_names_dict[row['true_label']]}")
        print(f"    ğŸ‘‰ ì˜ˆì¸¡ (Pred): {label_names_dict[row['pred_label']]}")
        print("-" * 40)
        print(f"[Prompt]: {row['prompt'][:200]}...") # ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ
        print(f"[Response A]: {row['response_a'][:200]}...")
        print(f"[Response B]: {row['response_b'][:200]}...")
        print("-" * 40 + "\n")
    
    # ì˜¤ë¥˜ ì „ì²´ CSVë¡œ ì €ì¥
    errors_csv_path = os.path.join(OUTPUT_DIR, "prediction_errors.csv")
    df_errors.to_csv(errors_csv_path, index=False, encoding='utf-8-sig')
    print(f"All prediction errors saved to: {errors_csv_path}")

    # 7. ë³´ì •ê¸° í›ˆë ¨ ë° ì €ì¥
    print("\n--- ğŸ“ˆ 3. Calibration Training ---")
    calibrators = {}
    for i in range(NUM_LABELS):
        iso_reg = IsotonicRegression(out_of_bounds='clip')
        y_cal = (y_true == i).astype(int)
        iso_reg.fit(y_probs[:, i], y_cal)
        calibrators[i] = iso_reg

    print("Calibration models trained.")
    
    # ë³´ì •ê¸° ì €ì¥
    calibrator_path = os.path.join(OUTPUT_DIR, "calibrators.joblib")
    joblib.dump(calibrators, calibrator_path)
    print(f"Calibrators saved to: {calibrator_path}")
    
    print("\nâœ… STAGE 2: Analysis and calibration complete.")

if __name__ == "__main__":
    main_analyze()