{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Model Extensions - Lightweight Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook fine-tunes a DeBERTa-small model using LoRA (Low-Rank Adaptation) for the preference prediction task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers peft accelerate bitsandbytes torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from peft import get_peft_model, LoraConfig\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv('dataset/train.csv')\n",
    "test_df = pd.read_csv('dataset/test.csv')\n",
    "submission_df = pd.read_csv('dataset/sample_submission.csv')\n",
    "\n",
    "# Prepare target variable\n",
    "conditions = [train_df['winner_model_a'] == 1, train_df['winner_model_b'] == 1, train_df['winner_tie'] == 1]\n",
    "choices = [0, 1, 2] # 0: model_a, 1: model_b, 2: tie\n",
    "train_df['label'] = np.select(conditions, choices, default=-1)\n",
    "train_df = train_df[train_df['label'] != -1].reset_index(drop=True)\n",
    "\n",
    "# Create combined text field\n",
    "def create_text(row):\n",
    "    return f\"\"\"prompt: {row['prompt']}\n",
    "\n",
    "response_a: {row['response_a']}\n",
    "\n",
    "response_b: {row['response_b']}\"\"\"\n",
    "\n",
    "train_df['text'] = train_df.apply(create_text, axis=1)\n",
    "test_df['text'] = test_df.apply(create_text, axis=1)\n",
    "\n",
    "# Split train data for validation\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_df['text'], train_df['label'], test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'microsoft/deberta-v3-small'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_texts.tolist(), truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(test_df['text'].tolist(), truncation=True, padding=True, max_length=512)\n",
    "\n",
    "class PreferenceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = PreferenceDataset(train_encodings, train_labels.tolist())\n",
    "val_dataset = PreferenceDataset(val_encodings, val_labels.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Setup and LoRA Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=3,\n",
    "    load_in_8bit=True,\n",
    "    device_map='auto'\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16, # Rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=['query_proj', 'value_proj'],\n",
    "    lora_dropout=0.05,\n",
    "    bias='none',\n",
    "    task_type=\"SEQ_CLS\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=1, # A single epoch for a quick baseline\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prediction and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "test_dataset = TestDataset(test_encodings)\n",
    "\n",
    "predictions = trainer.predict(test_dataset)\n",
    "probs = torch.nn.functional.softmax(torch.from_numpy(predictions.predictions), dim=-1).numpy()\n",
    "\n",
    "submission_df['winner_model_a'] = probs[:, 0]\n",
    "submission_df['winner_model_b'] = probs[:, 1]\n",
    "submission_df['winner_tie'] = probs[:, 2]\n",
    "\n",
    "submission_df.to_csv('submission_finetuned.csv', index=False)\n",
    "\n",
    "submission_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
