{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Step 2: Embedding-based Model"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This notebook implements an embedding-based model for predicting human preference of LLM responses.\n",
                "We will use a pre-trained sentence embedding model to construct prompt+response embeddings and train a classifier."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Install and Import Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install sentence-transformers torch"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/jeongseunghwan/opt/anaconda3/envs/transformer/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sentence_transformers import SentenceTransformer\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "import re"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>id</th>\n",
                            "      <th>model_a</th>\n",
                            "      <th>model_b</th>\n",
                            "      <th>prompt</th>\n",
                            "      <th>response_a</th>\n",
                            "      <th>response_b</th>\n",
                            "      <th>winner_model_a</th>\n",
                            "      <th>winner_model_b</th>\n",
                            "      <th>winner_tie</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>30192</td>\n",
                            "      <td>gpt-4-1106-preview</td>\n",
                            "      <td>gpt-4-0613</td>\n",
                            "      <td>[\"Is it morally right to try to have a certain...</td>\n",
                            "      <td>[\"The question of whether it is morally right ...</td>\n",
                            "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>53567</td>\n",
                            "      <td>koala-13b</td>\n",
                            "      <td>gpt-4-0613</td>\n",
                            "      <td>[\"What is the difference between marriage lice...</td>\n",
                            "      <td>[\"A marriage license is a legal document that ...</td>\n",
                            "      <td>[\"A marriage license and a marriage certificat...</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>65089</td>\n",
                            "      <td>gpt-3.5-turbo-0613</td>\n",
                            "      <td>mistral-medium</td>\n",
                            "      <td>[\"explain function calling. how would you call...</td>\n",
                            "      <td>[\"Function calling is the process of invoking ...</td>\n",
                            "      <td>[\"Function calling is the process of invoking ...</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>96401</td>\n",
                            "      <td>llama-2-13b-chat</td>\n",
                            "      <td>mistral-7b-instruct</td>\n",
                            "      <td>[\"How can I create a test set for a very rare ...</td>\n",
                            "      <td>[\"Creating a test set for a very rare category...</td>\n",
                            "      <td>[\"When building a classifier for a very rare c...</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>198779</td>\n",
                            "      <td>koala-13b</td>\n",
                            "      <td>gpt-3.5-turbo-0314</td>\n",
                            "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
                            "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
                            "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "       id             model_a              model_b  \\\n",
                            "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
                            "1   53567           koala-13b           gpt-4-0613   \n",
                            "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
                            "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
                            "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
                            "\n",
                            "                                              prompt  \\\n",
                            "0  [\"Is it morally right to try to have a certain...   \n",
                            "1  [\"What is the difference between marriage lice...   \n",
                            "2  [\"explain function calling. how would you call...   \n",
                            "3  [\"How can I create a test set for a very rare ...   \n",
                            "4  [\"What is the best way to travel from Tel-Aviv...   \n",
                            "\n",
                            "                                          response_a  \\\n",
                            "0  [\"The question of whether it is morally right ...   \n",
                            "1  [\"A marriage license is a legal document that ...   \n",
                            "2  [\"Function calling is the process of invoking ...   \n",
                            "3  [\"Creating a test set for a very rare category...   \n",
                            "4  [\"The best way to travel from Tel Aviv to Jeru...   \n",
                            "\n",
                            "                                          response_b  winner_model_a  \\\n",
                            "0  [\"As an AI, I don't have personal beliefs or o...               1   \n",
                            "1  [\"A marriage license and a marriage certificat...               0   \n",
                            "2  [\"Function calling is the process of invoking ...               0   \n",
                            "3  [\"When building a classifier for a very rare c...               1   \n",
                            "4  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
                            "\n",
                            "   winner_model_b  winner_tie  \n",
                            "0               0           0  \n",
                            "1               1           0  \n",
                            "2               0           1  \n",
                            "3               0           0  \n",
                            "4               1           0  "
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "train_df = pd.read_csv('dataset/train.csv')\n",
                "test_df = pd.read_csv('dataset/test.csv')\n",
                "submission_df = pd.read_csv('dataset/sample_submission.csv')\n",
                "\n",
                "train_df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Prepare Text and Generate Embeddings"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Batches:  42%|████▏     | 755/1797 [06:15<08:38,  2.01it/s]\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[5], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m test_df \u001b[39m=\u001b[39m prepare_text(test_df)\n\u001b[1;32m     13\u001b[0m \u001b[39m# Generate embeddings\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m train_embeddings_a \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mencode(train_df[\u001b[39m'\u001b[39;49m\u001b[39mtext_a\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mtolist(), show_progress_bar\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     15\u001b[0m train_embeddings_b \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mencode(train_df[\u001b[39m'\u001b[39m\u001b[39mtext_b\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtolist(), show_progress_bar\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m test_embeddings_a \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mencode(test_df[\u001b[39m'\u001b[39m\u001b[39mtext_a\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtolist(), show_progress_bar\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
                        "File \u001b[0;32m~/opt/anaconda3/envs/transformer/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:586\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    584\u001b[0m             \u001b[39m# fixes for #522 and #487 to avoid oom problems on gpu with large datasets\u001b[39;00m\n\u001b[1;32m    585\u001b[0m             \u001b[39mif\u001b[39;00m convert_to_numpy:\n\u001b[0;32m--> 586\u001b[0m                 embeddings \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39;49mcpu()\n\u001b[1;32m    588\u001b[0m         all_embeddings\u001b[39m.\u001b[39mextend(embeddings)\n\u001b[1;32m    590\u001b[0m all_embeddings \u001b[39m=\u001b[39m [all_embeddings[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39margsort(length_sorted_idx)]\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
                "\n",
                "def prepare_text(df):\n",
                "    # Clean up the prompt column\n",
                "    df['prompt'] = df['prompt'].apply(lambda x: re.sub(r'[\"\"|\"\"]', '', str(x)))\n",
                "    df['text_a'] = df['prompt'] + ' ' + df['response_a']\n",
                "    df['text_b'] = df['prompt'] + ' ' + df['response_b']\n",
                "    return df\n",
                "\n",
                "train_df = prepare_text(train_df)\n",
                "test_df = prepare_text(test_df)\n",
                "\n",
                "# Generate embeddings\n",
                "train_embeddings_a = model.encode(train_df['text_a'].tolist(), show_progress_bar=True)\n",
                "train_embeddings_b = model.encode(train_df['text_b'].tolist(), show_progress_bar=True)\n",
                "test_embeddings_a = model.encode(test_df['text_a'].tolist(), show_progress_bar=True)\n",
                "test_embeddings_b = model.encode(test_df['text_b'].tolist(), show_progress_bar=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Feature Engineering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Use the difference between embeddings as features\n",
                "X_train = train_embeddings_a - train_embeddings_b\n",
                "X_test = test_embeddings_a - test_embeddings_b"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Model Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create target variable\n",
                "conditions = [\n",
                "    train_df['winner_model_a'] == 1,\n",
                "    train_df['winner_model_b'] == 1,\n",
                "    train_df['winner_tie'] == 1\n",
                "]\n",
                "choices = [0, 1, 2] # 0: model_a, 1: model_b, 2: tie\n",
                "y_train = np.select(conditions, choices, default=-1)\n",
                "\n",
                "classifier = LogisticRegression(max_iter=1000)\n",
                "classifier.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Prediction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "predictions = classifier.predict_proba(X_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Submission"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "submission_df['winner_model_a'] = predictions[:, 0]\n",
                "submission_df['winner_model_b'] = predictions[:, 1]\n",
                "submission_df['winner_tie'] = predictions[:, 2]\n",
                "\n",
                "submission_df.to_csv('submission_embedding.csv', index=False)\n",
                "\n",
                "submission_df.head()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.9.21 ('transformer')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.21"
        },
        "vscode": {
            "interpreter": {
                "hash": "39d32efba01c30b0368d314f541dd447b1e0abc1c94139e3532a931796c9cc34"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
